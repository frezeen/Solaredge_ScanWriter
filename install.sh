#!/bin/bash
# SolarEdge Data Collector - Installation Script
# Usage: curl -sSL https://raw.githubusercontent.com/frezeen/Solaredge_ScanWriter/main/install.sh | bash

set -e

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() { echo -e "${GREEN}[$(date +'%H:%M:%S')] $1${NC}"; }
warn() { echo -e "${YELLOW}[$(date +'%H:%M:%S')] WARNING: $1${NC}"; }
error() { echo -e "${RED}[$(date +'%H:%M:%S')] ERROR: $1${NC}"; }
info() { echo -e "${BLUE}[$(date +'%H:%M:%S')] INFO: $1${NC}"; }

echo -e "${BLUE}"
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                SolarEdge Data Collector                      â•‘"
echo "â•‘                    Installation Script                       â•‘"
echo "â•‘              github.com/frezeen/Solaredge_ScanWriter         â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "${NC}"

# Require root
if [[ $EUID -ne 0 ]]; then
    error "This script must be run as root"
    echo "Please run: sudo $0"
    exit 1
fi

# Check if running on Debian/Ubuntu
if ! grep -qE "(Debian|Ubuntu)" /etc/os-release; then
    warn "This script is designed for Debian/Ubuntu. Proceeding anyway..."
fi

log "ğŸš€ Starting SolarEdge Data Collector installation..."

# Install basic dependencies
log "ğŸ“¦ Installing basic dependencies..."
apt-get update -qq

# Install packages in groups to handle potential failures
log "Installing core packages..."
apt-get install -y -qq curl wget git unzip >/dev/null 2>&1

log "Installing Python packages..."
apt-get install -y -qq python3 python3-pip python3-dev >/dev/null 2>&1

log "Installing build tools..."
apt-get install -y -qq build-essential >/dev/null 2>&1

log "Installing system utilities..."
apt-get install -y -qq nano htop systemd cron >/dev/null 2>&1

log "Installing repository tools..."
apt-get install -y -qq apt-transport-https gnupg ca-certificates >/dev/null 2>&1

# Clone project from GitHub
log "ğŸ“¥ Cloning project from GitHub..."
APP_DIR="/opt/Solaredge_ScanWriter"

# Rimuovi directory esistente se presente
if [[ -d "$APP_DIR" ]]; then
    log "âš ï¸  Directory esistente trovata, creando backup..."
    mv "$APP_DIR" "${APP_DIR}.backup.$(date +%Y%m%d_%H%M%S)"
fi

# Clone repository
if git clone https://github.com/frezeen/Solaredge_ScanWriter.git "$APP_DIR"; then
    log "âœ… Repository clonato con successo"
    
    # Entra nella directory
    cd "$APP_DIR"
    
    if [[ -d "$APP_DIR" ]]; then
        log "ğŸ”§ Starting installation process..."
        
        # Create required directories
        log "ğŸ“‚ Creating required directories..."
        mkdir -p "$APP_DIR"/{logs,cache,cookies,config,systemd,scripts,grafana}
        
        # Create requirements.txt if not exists
        if [[ ! -f "$APP_DIR/requirements.txt" ]]; then
            log "ğŸ“ Creating requirements.txt..."
            tee "$APP_DIR/requirements.txt" > /dev/null << 'REQS'
aiohttp>=3.8.0
influxdb-client>=1.36.0
PyYAML>=6.0
pymodbus==3.5.4
solaredge-modbus>=0.8.0
requests>=2.28.0
python-dotenv>=1.0.0
python-dateutil>=2.8.0
aiofiles>=22.1.0
jinja2>=3.1.0
aiohttp-jinja2>=1.5.0
pytz>=2023.3
REQS
        fi
        
        # Install Python dependencies system-wide
        log "ğŸ Installing Python dependencies..."
        pip3 install -r "$APP_DIR/requirements.txt" >/dev/null 2>&1
        
        # Install InfluxDB
        log "ğŸ—„ï¸ Installing InfluxDB..."
        rm -f /usr/share/keyrings/influxdata-archive-keyring.gpg
        curl -s https://repos.influxdata.com/influxdata-archive_compat.key | gpg --dearmor -o /usr/share/keyrings/influxdata-archive-keyring.gpg 2>/dev/null
        echo "deb [signed-by=/usr/share/keyrings/influxdata-archive-keyring.gpg] https://repos.influxdata.com/debian stable main" | tee /etc/apt/sources.list.d/influxdb.list >/dev/null
        
        apt-get update -qq >/dev/null 2>&1
        if ! apt-get install -y -qq influxdb2 >/dev/null 2>&1; then
            warn "Failed to install InfluxDB from repository, trying direct download..."
            INFLUX_VERSION="2.7.4"
            ARCH=$(dpkg --print-architecture)
            curl -LO "https://dl.influxdata.com/influxdb/releases/influxdb2_${INFLUX_VERSION}-1_${ARCH}.deb" >/dev/null 2>&1
            dpkg -i "influxdb2_${INFLUX_VERSION}-1_${ARCH}.deb" >/dev/null 2>&1 || apt-get install -f -y -qq
            rm -f "influxdb2_${INFLUX_VERSION}-1_${ARCH}.deb"
        fi
        
        systemctl enable influxdb >/dev/null 2>&1
        systemctl start influxdb >/dev/null 2>&1
        sleep 10
        
        # Configure InfluxDB
        log "âš™ï¸ Configuring InfluxDB..."
        INFLUX_USERNAME="admin"
        INFLUX_PASSWORD="solaredge123"
        INFLUX_ORG="fotovoltaico"
        INFLUX_BUCKET="Solaredge"
        INFLUX_BUCKET_REALTIME="Solaredge_Realtime"
        
        # Wait for InfluxDB to be ready
        log "Waiting for InfluxDB to be ready..."
        for i in {1..30}; do
            if curl -s http://localhost:8086/health >/dev/null 2>&1; then
                break
            fi
            if [[ $i -eq 30 ]]; then
                warn "InfluxDB may not be ready, continuing anyway..."
            fi
            sleep 2
        done
        
        # Install jq for JSON parsing
        apt-get install -y -qq jq >/dev/null 2>&1
        
        # Check if InfluxDB needs setup
        SETUP_STATUS=$(curl -s http://localhost:8086/api/v2/setup 2>/dev/null)
        
        if [[ -z "$SETUP_STATUS" ]] || echo "$SETUP_STATUS" | jq -e '.allowed == true' >/dev/null 2>&1; then
            log "Setting up InfluxDB initial configuration..."
            
            SETUP_RESPONSE=$(curl -s -X POST http://localhost:8086/api/v2/setup \
                -H "Content-Type: application/json" \
                -d "{
                    \"username\": \"$INFLUX_USERNAME\",
                    \"password\": \"$INFLUX_PASSWORD\",
                    \"org\": \"$INFLUX_ORG\",
                    \"bucket\": \"$INFLUX_BUCKET\"
                }")
            

            
            # Extract token using jq
            INFLUX_TOKEN=$(echo "$SETUP_RESPONSE" | jq -r '.auth.token // empty' 2>/dev/null)
            
            # Fallback: try different JSON structure
            if [[ -z "$INFLUX_TOKEN" || "$INFLUX_TOKEN" == "null" ]]; then
                INFLUX_TOKEN=$(echo "$SETUP_RESPONSE" | jq -r '.token // empty' 2>/dev/null)
            fi
            
            # Fallback: grep method
            if [[ -z "$INFLUX_TOKEN" || "$INFLUX_TOKEN" == "null" ]]; then
                INFLUX_TOKEN=$(echo "$SETUP_RESPONSE" | grep -o '"token":"[^"]*"' | cut -d'"' -f4)
            fi
            
            # Validate token
            if [[ -n "$INFLUX_TOKEN" && "$INFLUX_TOKEN" != "null" && ${#INFLUX_TOKEN} -gt 20 ]]; then
                log "âœ… InfluxDB configured successfully (${INFLUX_TOKEN:0:20}...)"
                
                # Get organization ID for bucket creation
                ORG_RESPONSE=$(curl -s -X GET http://localhost:8086/api/v2/orgs \
                    -H "Authorization: Token $INFLUX_TOKEN")
                INFLUX_ORG_ID=$(echo "$ORG_RESPONSE" | jq -r ".orgs[] | select(.name==\"$INFLUX_ORG\") | .id" 2>/dev/null)
                
                if [[ -n "$INFLUX_ORG_ID" && "$INFLUX_ORG_ID" != "null" ]]; then
                    # Create realtime bucket with 2-day retention
                    log "ğŸ“¦ Creating realtime bucket with 2-day retention..."
                    REALTIME_BUCKET_RESPONSE=$(curl -s -X POST http://localhost:8086/api/v2/buckets \
                        -H "Authorization: Token $INFLUX_TOKEN" \
                        -H "Content-Type: application/json" \
                        -d "{
                            \"orgID\": \"$INFLUX_ORG_ID\",
                            \"name\": \"$INFLUX_BUCKET_REALTIME\",
                            \"description\": \"Realtime data with 2-day retention\",
                            \"retentionRules\": [{
                                \"type\": \"expire\",
                                \"everySeconds\": 172800
                            }]
                        }")
                else
                    warn "Could not retrieve organization ID for bucket creation"
                fi
                
                if echo "$REALTIME_BUCKET_RESPONSE" | grep -q '"name"'; then
                    log "âœ… Realtime bucket created successfully"
                else
                    warn "Could not create realtime bucket automatically"
                fi
            else
                warn "âŒ Could not extract InfluxDB token from setup"
                INFLUX_TOKEN="SETUP_FAILED_CONFIGURE_MANUALLY"
            fi
        else
            log "InfluxDB already configured"
            INFLUX_TOKEN="ALREADY_CONFIGURED_GET_FROM_UI"
        fi
        
        # Install Grafana
        log "ğŸ“Š Installing Grafana..."
        rm -f /usr/share/keyrings/grafana-archive-keyring.gpg
        curl -s https://packages.grafana.com/gpg.key | gpg --dearmor -o /usr/share/keyrings/grafana-archive-keyring.gpg 2>/dev/null
        echo "deb [signed-by=/usr/share/keyrings/grafana-archive-keyring.gpg] https://packages.grafana.com/oss/deb stable main" | tee /etc/apt/sources.list.d/grafana.list >/dev/null
        
        apt-get update -qq >/dev/null 2>&1
        if ! apt-get install -y -qq grafana >/dev/null 2>&1; then
            warn "Failed to install Grafana from repository, trying direct download..."
            GRAFANA_VERSION="10.2.3"
            ARCH=$(dpkg --print-architecture)
            curl -LO "https://dl.grafana.com/oss/release/grafana_${GRAFANA_VERSION}_${ARCH}.deb" >/dev/null 2>&1
            dpkg -i "grafana_${GRAFANA_VERSION}_${ARCH}.deb" >/dev/null 2>&1 || apt-get install -f -y -qq
            rm -f "grafana_${GRAFANA_VERSION}_${ARCH}.deb"
        fi
        
        # Install Grafana plugins
        log "ğŸ”Œ Installing Grafana plugins..."
        grafana-cli plugins install fetzerch-sunandmoon-datasource >/dev/null 2>&1 || warn "Failed to install sun-and-moon plugin"
        grafana-cli plugins install grafana-clock-panel >/dev/null 2>&1 || warn "Failed to install clock plugin"
        
        systemctl enable grafana-server >/dev/null 2>&1
        systemctl start grafana-server >/dev/null 2>&1
        
        # Wait for Grafana to be ready
        log "Waiting for Grafana to be ready..."
        for i in {1..30}; do
            if curl -s http://localhost:3000/api/health >/dev/null 2>&1; then
                break
            fi
            if [[ $i -eq 30 ]]; then
                warn "Grafana may not be ready, continuing anyway..."
            fi
            sleep 2
        done
        
        # Configure Grafana data source
        log "âš™ï¸ Configuring Grafana data source..."
        GRAFANA_USER="admin"
        GRAFANA_PASS="admin"
        
        # Create InfluxDB data source in Grafana
        DATASOURCE_RESPONSE=$(curl -s -X POST http://localhost:3000/api/datasources \
            -u "$GRAFANA_USER:$GRAFANA_PASS" \
            -H "Content-Type: application/json" \
            -d "{
                \"name\": \"Solaredge\",
                \"type\": \"influxdb\",
                \"access\": \"proxy\",
                \"url\": \"http://localhost:8086\",
                \"jsonData\": {
                    \"version\": \"Flux\",
                    \"organization\": \"$INFLUX_ORG\",
                    \"defaultBucket\": \"$INFLUX_BUCKET\",
                    \"tlsSkipVerify\": true
                },
                \"secureJsonData\": {
                    \"token\": \"$INFLUX_TOKEN\"
                },
                \"isDefault\": true
            }" 2>/dev/null)
        
        if echo "$DATASOURCE_RESPONSE" | grep -q '"id"'; then
            log "âœ… Grafana InfluxDB data source configured successfully"
        else
            warn "Could not configure Grafana InfluxDB data source automatically. You can configure it manually in Grafana UI."
        fi
        
        # Configure Sun and Moon data source
        log "â˜€ï¸ Configuring Sun and Moon data source..."
        SUNMOON_RESPONSE=$(curl -s -X POST http://localhost:3000/api/datasources \
            -u "$GRAFANA_USER:$GRAFANA_PASS" \
            -H "Content-Type: application/json" \
            -d "{
                \"name\": \"Sun and Moon\",
                \"type\": \"fetzerch-sunandmoon-datasource\",
                \"access\": \"proxy\",
                \"jsonData\": {
                    \"latitude\": 40.8199,
                    \"longitude\": 14.3413
                }
            }" 2>/dev/null)
        
        if echo "$SUNMOON_RESPONSE" | grep -q '"id"'; then
            log "âœ… Grafana Sun and Moon data source configured successfully"
        else
            warn "Could not configure Sun and Moon data source automatically. You can configure it manually in Grafana UI."
        fi
        
        # Import Grafana dashboard with correct UIDs
        DASHBOARD_FILE="$APP_DIR/grafana/dashboard-solaredge.json"
        
        if [[ -f "$DASHBOARD_FILE" ]]; then
            log "ğŸ“Š Importing Grafana dashboard..."
            
            # Disable exit on error for this section
            set +e
            
            # Get data source UIDs
            DATASOURCES_LIST=$(curl -s http://localhost:3000/api/datasources -u "$GRAFANA_USER:$GRAFANA_PASS" 2>/dev/null)
            INFLUX_UID=$(echo "$DATASOURCES_LIST" | jq -r '.[] | select(.name=="Solaredge") | .uid' 2>/dev/null)
            SUNMOON_UID=$(echo "$DATASOURCES_LIST" | jq -r '.[] | select(.name=="Sun and Moon") | .uid' 2>/dev/null)
            
            if [[ -n "$INFLUX_UID" && "$INFLUX_UID" != "null" ]]; then
                log "Found Solaredge data source UID: $INFLUX_UID"
                
                # Create temporary dashboard file with updated UIDs
                TEMP_DASHBOARD="/tmp/dashboard-solaredge-temp.json"
                cp "$DASHBOARD_FILE" "$TEMP_DASHBOARD"
                
                # Replace data source UIDs in the dashboard JSON using jq for safer manipulation
                if command -v jq &> /dev/null; then
                    # Use jq to properly update UIDs
                    jq --arg uid "$INFLUX_UID" '
                        walk(
                            if type == "object" and .type == "influxdb" then
                                .uid = $uid
                            else
                                .
                            end
                        )
                    ' "$TEMP_DASHBOARD" > "${TEMP_DASHBOARD}.tmp" && mv "${TEMP_DASHBOARD}.tmp" "$TEMP_DASHBOARD"
                    
                    if [[ -n "$SUNMOON_UID" && "$SUNMOON_UID" != "null" ]]; then
                        log "Found Sun and Moon data source UID: $SUNMOON_UID"
                        jq --arg uid "$SUNMOON_UID" '
                            walk(
                                if type == "object" and .type == "fetzerch-sunandmoon-datasource" then
                                    .uid = $uid
                                else
                                    .
                                end
                            )
                        ' "$TEMP_DASHBOARD" > "${TEMP_DASHBOARD}.tmp" && mv "${TEMP_DASHBOARD}.tmp" "$TEMP_DASHBOARD"
                    fi
                else
                    # Fallback to sed if jq not available (should not happen as we install jq earlier)
                    sed -i.bak "s/\"uid\": \"[^\"]*\",.*\"type\": \"influxdb\"/\"uid\": \"$INFLUX_UID\", \"type\": \"influxdb\"/g" "$TEMP_DASHBOARD" 2>/dev/null
                    
                    if [[ -n "$SUNMOON_UID" && "$SUNMOON_UID" != "null" ]]; then
                        log "Found Sun and Moon data source UID: $SUNMOON_UID"
                        sed -i.bak "s/\"uid\": \"[^\"]*\",.*\"type\": \"fetzerch-sunandmoon-datasource\"/\"uid\": \"$SUNMOON_UID\", \"type\": \"fetzerch-sunandmoon-datasource\"/g" "$TEMP_DASHBOARD" 2>/dev/null
                    fi
                    rm -f "${TEMP_DASHBOARD}.bak"
                fi
                
                # Import dashboard via API using file directly
                # Create wrapper JSON for import
                IMPORT_PAYLOAD="/tmp/dashboard-import-payload.json"
                jq -n --slurpfile dashboard "$TEMP_DASHBOARD" '{
                    dashboard: $dashboard[0],
                    overwrite: true,
                    message: "Imported by installation script"
                }' > "$IMPORT_PAYLOAD" 2>/dev/null || {
                    warn "Failed to create import payload"
                    rm -f "$TEMP_DASHBOARD" "$IMPORT_PAYLOAD"
                    continue
                }
                
                IMPORT_RESPONSE=$(curl -s -X POST http://localhost:3000/api/dashboards/db \
                    -u "$GRAFANA_USER:$GRAFANA_PASS" \
                    -H "Content-Type: application/json" \
                    -d @"$IMPORT_PAYLOAD" 2>/dev/null)
                
                rm -f "$IMPORT_PAYLOAD"
                
                if echo "$IMPORT_RESPONSE" | grep -q '"status":"success"'; then
                    DASHBOARD_URL=$(echo "$IMPORT_RESPONSE" | jq -r '.url' 2>/dev/null)
                    log "âœ… Grafana dashboard imported successfully"
                    
                    if [[ -n "$DASHBOARD_URL" && "$DASHBOARD_URL" != "null" ]]; then
                        log "Dashboard URL: http://$(hostname -I | awk '{print $1}'):3000$DASHBOARD_URL"
                    fi
                else
                    warn "Could not import Grafana dashboard automatically. You can import it manually from grafana/dashboard-solaredge.json"
                fi
                
                rm -f "$TEMP_DASHBOARD"
            else
                warn "Could not retrieve data source UIDs. Dashboard import skipped."
            fi
        else
            warn "Dashboard file not found at $APP_DIR/grafana/dashboard-solaredge.json"
        fi
        
        # Re-enable exit on error
        set -e
        
        # Create .env file
        log "ğŸ“ Creating configuration file..."
        if [[ ! -f "$APP_DIR/.env" ]]; then
            tee "$APP_DIR/.env" > /dev/null << ENV
# SolarEdge ScanWriter - Environment Variables
# Generated by installation script

# === SOLAREDGE API CONFIGURATION ===
SOLAREDGE_API_KEY=REPLACE_WITH_YOUR_API_KEY
SOLAREDGE_USERNAME=your.email@example.com
SOLAREDGE_PASSWORD=REPLACE_WITH_YOUR_PASSWORD
SOLAREDGE_SITE_ID=123456
SOLAREDGE_API_BASE_URL=https://monitoringapi.solaredge.com
SOLAREDGE_BASE_URL=https://monitoring.solaredge.com
SOLAREDGE_LOGIN_URL=https://monitoring.solaredge.com/solaredge-apigw/api/login
API_TIMEOUT_SECONDS=30
API_RATE_LIMIT_SECONDS=1
API_RETRY_ATTEMPTS=3
API_RETRY_DELAY_SECONDS=2

# === SCHEDULER CONFIGURATION ===
SCHEDULER_API_DELAY_SECONDS=1
SCHEDULER_WEB_DELAY_SECONDS=2
SCHEDULER_REALTIME_DELAY_SECONDS=0
SCHEDULER_SKIP_DELAY_ON_CACHE_HIT=true

# === LOOP INTERVALS CONFIGURATION ===
LOOP_API_INTERVAL_MINUTES=15
LOOP_WEB_INTERVAL_MINUTES=15
LOOP_REALTIME_INTERVAL_SECONDS=5

# === REALTIME CONFIGURATION ===
REALTIME_MODBUS_HOST=192.168.1.100
REALTIME_MODBUS_PORT=1502
REALTIME_MODBUS_TIMEOUT=1
REALTIME_MODBUS_UNIT=1
MODBUS_RETRIES=3
MODBUS_ENABLED=true

# === INFLUXDB CONFIGURATION ===
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=$INFLUX_TOKEN
INFLUXDB_ORG=$INFLUX_ORG
INFLUXDB_BUCKET=Solaredge
INFLUXDB_BUCKET_REALTIME=Solaredge_Realtime
INFLUX_DRY_FILE=logs/influx_dry_points.jsonl
INFLUX_DRY_MODE=false
INFLUX_BATCH_SIZE=500
INFLUX_FLUSH_INTERVAL_MS=1000
INFLUX_JITTER_INTERVAL_MS=100
INFLUX_RETRY_INTERVAL_MS=1000
INFLUX_MAX_RETRIES=5

# === LOGGING CONFIGURATION ===
LOG_LEVEL=INFO
LOG_FILE_LOGGING=true
LOG_DIRECTORY=logs

# === GUI CONFIGURATION ===
GUI_HOST=127.0.0.1
GUI_PORT=8092

# === ENVIRONMENT SETTINGS ===
ENVIRONMENT=production
TIMEZONE=Europe/Rome

# === GLOBAL CONFIGURATION ===
GLOBAL_TIMEOUT_SECONDS=30
GLOBAL_WEB_REQUEST_TIMEOUT=40
GLOBAL_API_REQUEST_TIMEOUT=20
GLOBAL_BATCH_REQUEST_TIMEOUT=60
FILTER_DEBUG=false

# === WEB SCRAPING CONFIGURATION ===
SOLAREDGE_WEB_BASE_URL=https://monitoring.solaredge.com
SOLAREDGE_COOKIE_FILE=cookies/web_cookies.json
SOLAREDGE_SESSION_TIMEOUT_SECONDS=3600
ENV
        fi
        
        # Create systemd service
        log "ğŸ”§ Creating systemd service..."
        tee /etc/systemd/system/solaredge-scanwriter.service > /dev/null << 'SERVICE'
[Unit]
Description=Solaredge_ScanWriter (GUI + Loop 24/7)
After=network.target influxdb.service
Wants=network.target
Requires=influxdb.service

[Service]
Type=simple
User=root
Group=root
WorkingDirectory=/opt/Solaredge_ScanWriter
Environment=PYTHONPATH=/opt/Solaredge_ScanWriter

# Run with system Python
ExecStart=/usr/bin/python3 /opt/Solaredge_ScanWriter/main.py

# Restart configuration
Restart=always
RestartSec=10
StartLimitInterval=300
StartLimitBurst=5

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=solaredge-scanwriter

# Security settings
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ReadWritePaths=/opt/Solaredge_ScanWriter

[Install]
WantedBy=multi-user.target
SERVICE
        
        systemctl daemon-reload >/dev/null 2>&1
        
        # Configure log rotation
        log "ğŸ”„ Configuring log rotation..."
        if [[ -f "$APP_DIR/config/logrotate.conf" ]]; then
            cp "$APP_DIR/config/logrotate.conf" /etc/logrotate.d/solaredge-collector
            chown root:root /etc/logrotate.d/solaredge-collector
            chmod 644 /etc/logrotate.d/solaredge-collector
            
            # Update paths in logrotate config to match actual installation
            sed -i "s|/opt/solaredge-collector|$APP_DIR|g" /etc/logrotate.d/solaredge-collector
            
            # Update service names to match actual systemd service
            sed -i "s|solaredge-collector|solaredge-scanwriter|g" /etc/logrotate.d/solaredge-collector
            sed -i "s|solaredge-gui|solaredge-scanwriter|g" /etc/logrotate.d/solaredge-collector
            
            log "âœ… Log rotation configured - logs will be rotated daily and kept for 7 days"
        else
            warn "Logrotate configuration file not found at $APP_DIR/config/logrotate.conf, skipping log rotation setup"
        fi
        
        # Configure systemd journal retention
        log "ğŸ“° Configuring systemd journal retention..."
        
        # Create journald configuration directory if not exists
        mkdir -p /etc/systemd/journald.conf.d
        
        # Configure journal retention for our service specifically
        tee /etc/systemd/journald.conf.d/solaredge-retention.conf > /dev/null << 'JOURNAL'
# SolarEdge Data Collector - Journal Retention Configuration
# Keep journal logs for maximum 48 hours to prevent disk space issues

[Journal]
# Maximum retention time (48 hours)
MaxRetentionSec=48h

# Maximum disk usage for journal (100MB)
SystemMaxUse=100M

# Maximum size for individual journal files (10MB)
SystemMaxFileSize=10M

# Force sync every 5 minutes to ensure logs are written
SyncIntervalSec=5m

# Compress journal files
Compress=yes

# Forward to syslog (optional - disable if not needed)
ForwardToSyslog=no
JOURNAL
        
        # Apply journal configuration
        systemctl restart systemd-journald >/dev/null 2>&1 || warn "Could not restart journald service"
        
        # Configure journal vacuum for immediate cleanup of old logs
        log "ğŸ§¹ Cleaning up old journal logs..."
        journalctl --vacuum-time=48h >/dev/null 2>&1 || warn "Could not vacuum old journal logs"
        journalctl --vacuum-size=100M >/dev/null 2>&1 || warn "Could not vacuum journal by size"
        
        log "âœ… Journal retention configured - systemd logs kept for max 48 hours (100MB limit)"
        
        # Optional: Create cron job for automatic journal cleanup (runs daily at 3 AM)
        log "â° Setting up automatic journal cleanup..."
        CRON_JOB="0 3 * * * /usr/bin/journalctl --vacuum-time=48h --vacuum-size=100M >/dev/null 2>&1"
        
        # Add cron job for root user (journalctl requires root privileges)
        if ! crontab -l 2>/dev/null | grep -q "journalctl --vacuum"; then
            (crontab -l 2>/dev/null; echo "$CRON_JOB") | crontab -
            log "âœ… Daily journal cleanup scheduled at 3:00 AM"
        else
            log "â„¹ï¸ Journal cleanup cron job already exists"
        fi
        
        # Create helper scripts
        log "ğŸ“ Creating helper scripts..."
        tee "$APP_DIR/test.sh" > /dev/null << 'TEST'
#!/bin/bash
# SolarEdge Installation Test Script

cd /opt/Solaredge_ScanWriter

echo "=== SolarEdge Installation Test ==="
echo ""

# Test System Python
echo "ğŸ System Python:"
if command -v python3 &> /dev/null; then
    echo "âœ… System Python exists"
    echo "  Python path: $(which python3)"
    echo "  Python version: $(python3 --version)"
else
    echo "âŒ System Python not found"
fi
echo ""

# Test installed packages
echo "ğŸ“¦ Installed Python packages:"
if command -v pip3 &> /dev/null; then
    pip3 list | grep -E "(aiohttp|influxdb|yaml|pymodbus|solaredge)" | head -10
else
    echo "âŒ pip3 not found"
fi
echo ""

# Test services
echo "ğŸ”§ Services status:"
echo "  SolarEdge: $(systemctl is-active solaredge-scanwriter 2>/dev/null || echo 'not-found')"
echo "  InfluxDB: $(systemctl is-active influxdb 2>/dev/null || echo 'not-found')"
echo "  Grafana: $(systemctl is-active grafana-server 2>/dev/null || echo 'not-found')"
echo ""

# Test directories and permissions
echo "ğŸ“ Directory structure:"
ls -la /opt/Solaredge_ScanWriter/ | head -10
echo ""

# Test configuration
echo "âš™ï¸ Configuration:"
if [[ -f .env ]]; then
    echo "âœ… .env file exists"
    echo "  Key variables:"
    grep -E "^[A-Z].*=" .env | head -5 | sed 's/=.*/=***/' | sed 's/^/    /'
else
    echo "âŒ .env file missing"
fi
echo ""

# Test main application
echo "ğŸ§ª Application test:"
if [[ -f main.py ]]; then
    echo "âœ… main.py exists"
    if python3 -c "import main" 2>/dev/null; then
        echo "âœ… Main module imports successfully"
    else
        echo "âš ï¸ Main module has import issues (check dependencies)"
    fi
else
    echo "âŒ main.py not found"
fi

echo ""
echo "=== Test Complete ==="
TEST
        
        tee "$APP_DIR/status.sh" > /dev/null << 'STATUS'
#!/bin/bash
# SolarEdge Service Status Script

echo "=== Solaredge_ScanWriter Status ==="
echo ""

# Service status (only if service is loaded)
echo "ğŸ”§ Service Status:"
if systemctl is-enabled solaredge-scanwriter >/dev/null 2>&1; then
    systemctl status solaredge-scanwriter --no-pager 2>/dev/null || echo "  Service not started yet"
else
    echo "  Service created but not enabled yet"
    echo "  Run: systemctl enable --now solaredge-scanwriter"
fi
echo ""

# Process information
echo "ğŸ” Process Information:"
if pgrep -f "solaredge" >/dev/null; then
    echo "âœ… SolarEdge processes running:"
    ps aux | grep -E "(solaredge|main\.py)" | grep -v grep | head -5
else
    echo "âŒ No SolarEdge processes found"
fi
echo ""

# System Python check
echo "ğŸ System Python:"
if command -v python3 &> /dev/null; then
    echo "âœ… System Python available"
    echo "  Python: $(python3 --version)"
else
    echo "âŒ System Python not found"
fi
echo ""

# Recent logs
echo "ğŸ“‹ Recent Logs (last 15 lines):"
journalctl -u solaredge-scanwriter --lines=15 --no-pager
echo ""

# Log files
echo "ğŸ“ Log Files:"
if [[ -d /opt/Solaredge_ScanWriter/logs ]]; then
    find /opt/Solaredge_ScanWriter/logs -name "*.log" -type f 2>/dev/null | head -5 | while read file; do
        size=$(du -h "$file" 2>/dev/null | cut -f1)
        modified=$(stat -c %y "$file" 2>/dev/null | cut -d' ' -f1)
        echo "  â€¢ $(basename "$file"): $size (modified: $modified)"
    done
else
    echo "  âŒ Log directory not found"
fi
STATUS

        # Create manual run script for testing
        tee "$APP_DIR/run-manual.sh" > /dev/null << 'MANUAL'
#!/bin/bash
# Manual run script for testing SolarEdge application

cd /opt/Solaredge_ScanWriter

echo "ğŸš€ SolarEdge Manual Run Script"
echo "============================="
echo ""

# Show Python info
echo "ğŸ Python Environment:"
echo "  Python: $(which python3)"
echo "  Version: $(python3 --version)"
echo ""

# Show available options
echo "ğŸ“‹ Available run modes:"
echo "  1. GUI mode (default): python3 main.py"
echo "  2. API test: python3 main.py --api"
echo "  3. Web test: python3 main.py --web"
echo "  4. Realtime test: python3 main.py --realtime"
echo "  5. History mode: python3 main.py --history"
echo ""

# Ask user what to run
read -p "Enter mode number (1-5) or press Enter for GUI mode: " choice

case $choice in
    2)
        echo "ğŸ”„ Running API test..."
        python3 main.py --api
        python main.py --api
        ;;
    3)
        echo "ğŸ”„ Running Web test..."
        python main.py --web
        ;;
    4)
        python3 main.py --api
        ;;
    3)
        echo "ğŸ”„ Running Web test..."
        python3 main.py --web
        ;;
    4)
        echo "ğŸ”„ Running Realtime test..."
        python3 main.py --realtime
        ;;
    5)
        echo "ğŸ”„ Running History mode..."
        python3 main.py --history
        ;;
    *)
        echo "ğŸ”„ Running GUI mode..."
        echo "   Access GUI at: http://$(hostname -I | awk '{print $1}'):8092"
        echo "   Press Ctrl+C to stop"
        echo ""
        python3 main.py
        ;;
esac
MANUAL

        # Create bucket verification script
        tee "$APP_DIR/check-buckets.sh" > /dev/null << 'BUCKETS'
#!/bin/bash
# Script per verificare configurazione bucket InfluxDB

source .env 2>/dev/null || { echo "âŒ File .env non trovato"; exit 1; }

echo "ğŸ—„ï¸ Verifica Configurazione Bucket InfluxDB"
echo "=========================================="
echo ""
echo "ğŸ“‹ Configurazione:"
echo "  URL: $INFLUXDB_URL"
echo "  Org: $INFLUXDB_ORG"
echo "  Bucket principale: $INFLUXDB_BUCKET"
echo "  Bucket realtime: $INFLUXDB_BUCKET_REALTIME"
echo ""

if command -v curl &> /dev/null; then
    echo "ğŸ” Verifica connessione InfluxDB..."
    if curl -s "$INFLUXDB_URL/health" >/dev/null 2>&1; then
        echo "âœ… InfluxDB raggiungibile"
        
        if command -v jq &> /dev/null; then
            echo ""
            echo "ğŸ“¦ Bucket esistenti:"
            BUCKETS=$(curl -s -H "Authorization: Token $INFLUXDB_TOKEN" "$INFLUXDB_URL/api/v2/buckets" 2>/dev/null)
            
            if echo "$BUCKETS" | jq -e '.buckets' >/dev/null 2>&1; then
                echo "$BUCKETS" | jq -r '.buckets[] | "  â€¢ \(.name) (retention: \(if .retentionRules[0].everySeconds then "\(.retentionRules[0].everySeconds)s" else "infinite" end))"' 2>/dev/null || echo "  Errore parsing bucket"
            else
                echo "  âŒ Errore recupero bucket (verifica token)"
            fi
        else
            echo "  âš ï¸  jq non installato - installa per dettagli bucket"
        fi
    else
        echo "âŒ InfluxDB non raggiungibile"
    fi
else
    echo "âš ï¸  curl non disponibile - verifica manuale necessaria"
fi

echo ""
echo "ğŸ’¡ I bucket vengono creati automaticamente durante l'installazione"
BUCKETS

        # Create logrotate verification script
        tee "$APP_DIR/check-logrotate.sh" > /dev/null << 'LOGROTATE'
#!/bin/bash
# Script per verificare configurazione logrotate

echo "ğŸ”„ Verifica Configurazione Log Rotation"
echo "======================================"
echo ""

# Check if logrotate config exists
if [[ -f /etc/logrotate.d/solaredge-collector ]]; then
    echo "âœ… File configurazione logrotate trovato: /etc/logrotate.d/solaredge-collector"
    echo ""
    echo "ğŸ“‹ Configurazione attuale:"
    cat /etc/logrotate.d/solaredge-collector
    echo ""
    
    # Test logrotate configuration
    echo "ğŸ§ª Test configurazione logrotate..."
    if sudo logrotate -d /etc/logrotate.d/solaredge-collector 2>/dev/null; then
        echo "âœ… Configurazione logrotate valida"
    else
        echo "âŒ Errore nella configurazione logrotate"
    fi
    
    echo ""
    echo "ğŸ“ File di log attuali:"
    find /opt/Solaredge_ScanWriter/logs -name "*.log" -type f 2>/dev/null | head -10 | while read file; do
        size=$(du -h "$file" 2>/dev/null | cut -f1)
        echo "  â€¢ $(basename "$file"): $size"
    done
    
    echo ""
    echo "ğŸ—‚ï¸ File di log ruotati (se presenti):"
    find /opt/Solaredge_ScanWriter/logs -name "*.log.*" -type f 2>/dev/null | head -5 | while read file; do
        size=$(du -h "$file" 2>/dev/null | cut -f1)
        echo "  â€¢ $(basename "$file"): $size"
    done
    
else
    echo "âŒ File configurazione logrotate non trovato"
    echo "   Dovrebbe essere in: /etc/logrotate.d/solaredge-collector"
fi

echo ""
echo "ğŸ’¡ La rotazione dei log avviene automaticamente ogni giorno via cron"
echo "ğŸ’¡ Per forzare una rotazione manuale: sudo logrotate -f /etc/logrotate.d/solaredge-collector"
LOGROTATE

        # Create journal management script
        tee "$APP_DIR/manage-journal.sh" > /dev/null << 'JOURNAL_SCRIPT'
#!/bin/bash
# Script per gestire i log systemd journal

echo "ğŸ“° Gestione Journal Systemd"
echo "==========================="
echo ""

case "${1:-status}" in
    "status"|"")
        echo "ğŸ“Š Stato attuale del journal:"
        echo ""
        
        # Journal disk usage
        echo "ğŸ’¾ Utilizzo disco journal:"
        sudo journalctl --disk-usage 2>/dev/null || echo "  Errore recupero utilizzo disco"
        echo ""
        
        # Journal configuration
        echo "âš™ï¸ Configurazione journal:"
        if [[ -f /etc/systemd/journald.conf.d/solaredge-retention.conf ]]; then
            echo "  âœ… Configurazione personalizzata attiva:"
            grep -E "^[A-Z]" /etc/systemd/journald.conf.d/solaredge-retention.conf | sed 's/^/    /'
        else
            echo "  âš ï¸ Configurazione personalizzata non trovata"
        fi
        echo ""
        
        # Recent logs for our service
        echo "ğŸ“‹ Log recenti del servizio (ultime 10 righe):"
        sudo journalctl -u solaredge-scanwriter --lines=10 --no-pager 2>/dev/null || echo "  Servizio non trovato o non attivo"
        echo ""
        
        # Journal files info
        echo "ğŸ“ File journal attuali:"
        sudo find /var/log/journal -name "*.journal*" -type f 2>/dev/null | head -5 | while read file; do
            size=$(sudo du -h "$file" 2>/dev/null | cut -f1)
            modified=$(sudo stat -c %y "$file" 2>/dev/null | cut -d' ' -f1)
            echo "  â€¢ $(basename "$file"): $size (modificato: $modified)"
        done
        ;;
        
    "clean")
        echo "ğŸ§¹ Pulizia journal logs..."
        echo ""
        
        echo "Prima della pulizia:"
        sudo journalctl --disk-usage
        echo ""
        
        # Clean logs older than 48 hours
        echo "Rimozione log piÃ¹ vecchi di 48 ore..."
        sudo journalctl --vacuum-time=48h
        echo ""
        
        # Limit total size to 100MB
        echo "Limitazione dimensione totale a 100MB..."
        sudo journalctl --vacuum-size=100M
        echo ""
        
        echo "Dopo la pulizia:"
        sudo journalctl --disk-usage
        ;;
        
    "logs")
        echo "ğŸ“‹ Log del servizio SolarEdge (ultime 50 righe):"
        echo ""
        sudo journalctl -u solaredge-scanwriter --lines=50 --no-pager
        ;;
        
    "follow")
        echo "ğŸ“¡ Monitoraggio log in tempo reale (Ctrl+C per uscire):"
        echo ""
        sudo journalctl -u solaredge-scanwriter -f
        ;;
        
    "help")
        echo "Utilizzo: $0 [comando]"
        echo ""
        echo "Comandi disponibili:"
        echo "  status  - Mostra stato journal e configurazione (default)"
        echo "  clean   - Pulisce log vecchi (>48h) e limita dimensione"
        echo "  logs    - Mostra log recenti del servizio"
        echo "  follow  - Monitora log in tempo reale"
        echo "  help    - Mostra questo aiuto"
        ;;
        
    *)
        echo "âŒ Comando non riconosciuto: $1"
        echo "Usa '$0 help' per vedere i comandi disponibili"
        exit 1
        ;;
esac
JOURNAL_SCRIPT
        
        chmod +x "$APP_DIR"/{test.sh,status.sh,check-buckets.sh,check-logrotate.sh,manage-journal.sh}
        
        # Configure executable permissions for all scripts
        log "ğŸ”§ Configuring script permissions..."
        EXECUTABLE_FILES=(
            "update.sh"
            "install.sh"
            "setup-permissions.sh"
            "scripts/smart_update.py"
            "scripts/cleanup_logs.sh"
            "test.sh"
            "status.sh"
            "check-buckets.sh"
            "check-logrotate.sh"
            "manage-journal.sh"
            "main.py"
            "run-manual.sh"
            "# venv.sh removed"
        )
        
        for file in "${EXECUTABLE_FILES[@]}"; do
            if [[ -f "$APP_DIR/$file" ]]; then
                chmod +x "$APP_DIR/$file"
            fi
        done
        
        # Configure directory and file permissions for config files
        log "ğŸ”§ Configuring config directory permissions..."
        chmod -R 755 "$APP_DIR/config"
        chmod -R 664 "$APP_DIR/config"/*.yaml "$APP_DIR/config"/*/*.yaml 2>/dev/null || true
        
        # Ensure specific directories have correct permissions
        CONFIG_DIRS=(
            "config"
            "config/sources"
            "logs"
            "cache"
            "cookies"
            "storage"
            "backups"
        )
        
        for dir in "${CONFIG_DIRS[@]}"; do
            if [[ -d "$APP_DIR/$dir" ]] || mkdir -p "$APP_DIR/$dir"; then
                chmod -R 755 "$APP_DIR/$dir"
            fi
        done
        
        # Ensure config files are writable by the solaredge user
        CONFIG_FILES=(
            "config/main.yaml"
            "config/sources/api_endpoints.yaml"
            "config/sources/web_endpoints.yaml"
            "config/sources/modbus_endpoints.yaml"
            ".env"
        )
        
        for file in "${CONFIG_FILES[@]}"; do
            if [[ -f "$APP_DIR/$file" ]]; then
                chmod 664 "$APP_DIR/$file"
            fi
        done
        
        # Setup Git hooks for automatic permission restoration
        if [[ -d "$APP_DIR/.git" ]]; then
            log "ğŸ“ Setting up Git hooks for automatic permissions..."
            
            # Create Git hooks directory if not exists
            mkdir -p "$APP_DIR/.git/hooks"
            
            # Copy hooks from .githooks if they exist
            if [[ -d "$APP_DIR/.githooks" ]]; then
                cp "$APP_DIR/.githooks"/* "$APP_DIR/.git/hooks/" 2>/dev/null || true
                chmod +x "$APP_DIR/.git/hooks"/* 2>/dev/null || true
            fi
            
            # Configure Git to preserve file permissions
            if [[ $EUID -eq 0 ]]; then
                su solaredge -c "cd $APP_DIR && git config core.filemode true" 2>/dev/null || true
            else
                sudo -u solaredge bash -c "cd $APP_DIR && git config core.filemode true" 2>/dev/null || true
            fi
        fi
        
        # Configure firewall
        if command -v ufw &> /dev/null; then
            log "ğŸ”¥ Configuring firewall..."
            ufw --force enable >/dev/null 2>&1 || true
            ufw allow 8092/tcp comment "SolarEdge GUI" >/dev/null 2>&1 || true
            ufw allow 8086/tcp comment "InfluxDB" >/dev/null 2>&1 || true
            ufw allow 3000/tcp comment "Grafana" >/dev/null 2>&1 || true
        fi
        
        log "âœ… Installation completed successfully!"
        echo ""
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘           ğŸ‰ Installation Complete!                       â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "ğŸ“‹ System Information:"
        echo "  â€¢ Installation path: /opt/Solaredge_ScanWriter"
        echo "  â€¢ Service name: solaredge-scanwriter"
        echo "  â€¢ Running as: root"
        echo ""
        echo "ğŸŒ Access URLs:"
        echo "  â€¢ SolarEdge GUI: http://$(hostname -I | awk '{print $1}'):8092"
        echo "  â€¢ InfluxDB UI:   http://$(hostname -I | awk '{print $1}'):8086"
        echo "  â€¢ Grafana:       http://$(hostname -I | awk '{print $1}'):3000"
        echo ""
        echo "ğŸ”‘ Default Credentials:"
        echo "  â€¢ InfluxDB: admin / solaredge123"
        echo "  â€¢ Grafana:  admin / admin (change on first login)"
        echo ""
        echo "ğŸ“ InfluxDB Token (save this!):"
        echo "  Token: $INFLUX_TOKEN"
        echo "  Already configured in .env file"
        echo ""
        echo "âš™ï¸ Next Steps:"
        echo ""
        echo "1ï¸âƒ£  Configure SolarEdge credentials:"
        echo "    nano /opt/Solaredge_ScanWriter/.env"
        echo "    # Update these values:"
        echo "    #   SOLAREDGE_API_KEY=your_api_key"
        echo "    #   SOLAREDGE_USERNAME=your_email"
        echo "    #   SOLAREDGE_PASSWORD=your_password"
        echo "    #   SOLAREDGE_SITE_ID=your_site_id"
        echo ""
        echo "2ï¸âƒ£  Verify InfluxDB token (if you get 401 errors):"
        echo "    cat /opt/Solaredge_ScanWriter/.env | grep INFLUXDB_TOKEN"
        echo "    # Or get it from InfluxDB UI â†’ Data â†’ API Tokens"
        echo ""
        echo "3ï¸âƒ£  Start the service:"
        echo "    systemctl enable --now solaredge-scanwriter"
        echo ""
        echo "4ï¸âƒ£  Monitor the logs:"
        echo "    journalctl -u solaredge-scanwriter -f"
        echo ""
        echo "ğŸ› ï¸  Utility Scripts (in /opt/Solaredge_ScanWriter):"
        echo "  â€¢ ./test.sh           - Test installation"
        echo "  â€¢ ./status.sh         - Check service status"
        echo "  â€¢ ./run-manual.sh     - Run manually for testing"
        echo "  â€¢ ./check-buckets.sh  - Verify InfluxDB buckets"
        echo "  â€¢ ./update.sh         - Update system"
        echo ""
        echo "âœ¨ Features Configured:"
        echo "  âœ… Dual bucket setup (Solaredge + Solaredge_Realtime)"
        echo "  âœ… 2-day retention for realtime data"
        echo "  âœ… Log rotation (7 days main, 3 days debug)"
        echo "  âœ… Journal retention (48h, 100MB limit)"
        echo "  âœ… System Python with global dependencies"
        echo "  âœ… Grafana dashboard pre-configured"
        echo ""
        echo "ğŸ“š Documentation:"
        echo "  â€¢ README: /opt/Solaredge_ScanWriter/README.md"
        echo "  â€¢ API Docs: /opt/Solaredge_ScanWriter/docs/"
        echo ""
        echo "âš ï¸  Important: Configure .env before starting the service!"
        echo ""
        
        # Create installation report file
        REPORT_FILE="/opt/Solaredge_ScanWriter/install_report.md"
        cat > "$REPORT_FILE" << REPORT_EOF
# SolarEdge Data Collector - Installation Report

**Installation Date:** $(date '+%Y-%m-%d %H:%M:%S')  
**Hostname:** $(hostname)  
**IP Address:** $(hostname -I | awk '{print $1}')

---

## ğŸ“‹ System Information

- **Installation Path:** /opt/Solaredge_ScanWriter
- **Service Name:** solaredge-scanwriter
- **Running As:** root
- **Python Version:** $(python3 --version)

---

## ğŸŒ Access URLs

| Service | URL | Credentials |
|---------|-----|-------------|
| SolarEdge GUI | http://$(hostname -I | awk '{print $1}'):8092 | - |
| InfluxDB UI | http://$(hostname -I | awk '{print $1}'):8086 | admin / solaredge123 |
| Grafana | http://$(hostname -I | awk '{print $1}'):3000 | admin / admin |

---

## ğŸ”‘ InfluxDB Configuration

**Token:** \`$INFLUX_TOKEN\`

**Organization:** fotovoltaico  
**Buckets:**
- \`Solaredge\` - Main data (API/Web)
- \`Solaredge_Realtime\` - Realtime data (2-day retention)

> âš ï¸ **Important:** This token is already configured in \`.env\` file.  
> If you get 401 errors, verify the token with:
> \`\`\`bash
> cat /opt/Solaredge_ScanWriter/.env | grep INFLUXDB_TOKEN
> \`\`\`

---

## âš™ï¸ Next Steps

### 1ï¸âƒ£ Configure SolarEdge Credentials

Edit the \`.env\` file:
\`\`\`bash
nano /opt/Solaredge_ScanWriter/.env
\`\`\`

Update these values:
\`\`\`bash
SOLAREDGE_API_KEY=your_api_key_here
SOLAREDGE_USERNAME=your_email@example.com
SOLAREDGE_PASSWORD=your_password_here
SOLAREDGE_SITE_ID=your_site_id_here
\`\`\`

### 2ï¸âƒ£ Start the Service

\`\`\`bash
systemctl enable --now solaredge-scanwriter
\`\`\`

### 3ï¸âƒ£ Monitor the Logs

\`\`\`bash
journalctl -u solaredge-scanwriter -f
\`\`\`

---

## ğŸ› ï¸ Utility Scripts

All scripts are located in \`/opt/Solaredge_ScanWriter/\`:

| Script | Description |
|--------|-------------|
| \`./test.sh\` | Test installation and dependencies |
| \`./status.sh\` | Check service status and logs |
| \`./run-manual.sh\` | Run manually for testing |
| \`./check-buckets.sh\` | Verify InfluxDB buckets |
| \`./check-logrotate.sh\` | Verify log rotation |
| \`./manage-journal.sh\` | Manage systemd journal logs |
| \`./update.sh\` | Update system (preserves config) |

---

## âœ¨ Features Configured

- âœ… Dual bucket setup (Solaredge + Solaredge_Realtime)
- âœ… 2-day retention for realtime data
- âœ… Log rotation (7 days main, 3 days debug)
- âœ… Journal retention (48h, 100MB limit)
- âœ… System Python with global dependencies
- âœ… Grafana dashboard pre-configured

---

## ğŸ“š Documentation

- **README:** /opt/Solaredge_ScanWriter/README.md
- **API Docs:** /opt/Solaredge_ScanWriter/docs/
- **Configuration:** /opt/Solaredge_ScanWriter/.env

---

## ğŸ”§ Troubleshooting

### Service won't start
\`\`\`bash
# Check service status
systemctl status solaredge-scanwriter

# View logs
journalctl -u solaredge-scanwriter -n 50
\`\`\`

### InfluxDB 401 Unauthorized
\`\`\`bash
# Verify token in .env
cat .env | grep INFLUXDB_TOKEN

# Or get token from InfluxDB UI
# Go to: http://YOUR_IP:8086 â†’ Data â†’ API Tokens
\`\`\`

### Python dependencies issues
\`\`\`bash
# Reinstall dependencies
pip3 install -r requirements.txt
\`\`\`

---

## ğŸ“ Support

- **GitHub:** https://github.com/frezeen/Solaredge_ScanWriter
- **Issues:** https://github.com/frezeen/Solaredge_ScanWriter/issues

---

*Report generated by install.sh on $(date)*
REPORT_EOF

        chmod 644 "$REPORT_FILE"
        
        echo "ğŸ“„ Installation report saved to: $REPORT_FILE"
        echo ""
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  ğŸ’¡ To start working, run:                                â•‘"
        echo "â•‘                                                            â•‘"
        echo "â•‘     cd /opt/Solaredge_ScanWriter                          â•‘"
        echo "â•‘                                                            â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        
    else
        error "Git clone failed or directory not created"
        exit 1
    fi
else
    error "Failed to clone repository from GitHub"
    exit 1
fi



